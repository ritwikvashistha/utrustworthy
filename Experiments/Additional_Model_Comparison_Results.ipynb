{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5VtMIqmjmh5"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit, vmap, grad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "bqW22dH1sLai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Nefy0ZJZq-bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1soqUvyymXi1"
      },
      "source": [
        "# Defining functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFGDkzQloSTX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrueQi_9mZuc"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, brier_score_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def utility(p, y_true, th, a11, a12, a21):\n",
        "\n",
        "    Ypred = 0.0 * y_true\n",
        "    Ypred[p > th] = 1.0\n",
        "\n",
        "    # TP and TN contribution to the utility function\n",
        "    Tmask = Ypred == y_true\n",
        "    U_T = np.sum(Tmask)\n",
        "\n",
        "    # FP contribution to the utility function\n",
        "    Fmask = ~Tmask\n",
        "    Pmask = Ypred == 1.0\n",
        "    U_FP = np.sum(Fmask * Pmask)\n",
        "\n",
        "    # FN contribution to the utility function\n",
        "    Nmask = ~Pmask\n",
        "    U_FN = np.sum(Fmask * Nmask)\n",
        "\n",
        "    U = (a11 * U_T - a12 * U_FP - a21 * U_FN) / len(p)\n",
        "\n",
        "    return U\n",
        "\n",
        "def max_utility(y_true, y_pred):\n",
        "\n",
        "    threshold_vec = np.linspace(0.0, 1.0, 1001)\n",
        "\n",
        "    # make utility curve\n",
        "    u = [utility(y_pred, y_true, th, 1, 0, 0) for th in threshold_vec]\n",
        "\n",
        "    return np.max(u)"
      ],
      "metadata": {
        "id": "bOEd6UKrHeIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NetTrustScore(y_true, p):\n",
        "    alpha = 1.0\n",
        "    beta = 1.0\n",
        "\n",
        "    y_hat = np.where(p >= 0.5, 1, 0)\n",
        "    A=[]\n",
        "    B=[]\n",
        "    for i in range(0,p.shape[0]):\n",
        "      if(y_hat[i]==y_true[i]):\n",
        "        A.append(np.power(p[i],alpha))\n",
        "      else:\n",
        "        A.append(0)\n",
        "\n",
        "      if(y_hat[i]!=y_true[i]):\n",
        "        B.append(np.power(1.0 - p[i],beta))\n",
        "      else:\n",
        "        B.append(0)\n",
        "\n",
        "    return ( np.sum(A) + np.sum(B) ) / y_true.shape[0]"
      ],
      "metadata": {
        "id": "IipG3cVmenDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Model Comparision Results"
      ],
      "metadata": {
        "id": "zwYvDYihEKfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Breast Cancer Dataset"
      ],
      "metadata": {
        "id": "wNbYBmk-vXry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n"
      ],
      "metadata": {
        "id": "aeWKxYxuvcD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store test statistics for each split\n",
        "auc_scores = []\n",
        "accuracy_scores = []\n",
        "brier_scores = []\n",
        "NetTrust_score = []\n",
        "max_utility_scores = []\n",
        "\n",
        "# Set the number of sims\n",
        "num_sims = 50\n",
        "\n",
        "# Initialize classifiers\n",
        "rf_classifier = RandomForestClassifier(max_depth=3, n_estimators=200)\n",
        "logreg_classifier = LogisticRegression()\n",
        "knn_classifier = KNeighborsClassifier(weights = 'distance', n_neighbors=250)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Perform 20 random splits and evaluate each classifier\n",
        "for i in range(num_sims):\n",
        "\n",
        "    print(\"Iteration %i\"%i)\n",
        "\n",
        "    # Randomly split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45323+i*543)\n",
        "\n",
        "    # Train the classifiers\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    logreg_classifier.fit(X_train, y_train)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and probability estimates\n",
        "    rf_proba = rf_classifier.predict_proba(X_test)\n",
        "    logreg_proba = logreg_classifier.predict_proba(X_test)\n",
        "    knn_predictions = knn_classifier.predict_proba(X_test)\n",
        "    nb_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "    # Calculate test statistics for each classifier\n",
        "    rf_auc = roc_auc_score(y_test, rf_proba[:, 1])\n",
        "    rf_accuracy = accuracy_score(y_test, rf_classifier.predict(X_test))\n",
        "    rf_brier_score = brier_score_loss(y_test, rf_proba[:, 1])\n",
        "    rf_NetTrust_score = NetTrustScore(y_test, rf_proba[:, 1][:, np.newaxis])\n",
        "    rf_max_u_score = max_utility(y_test, rf_proba[:, 1])\n",
        "\n",
        "    logreg_auc = roc_auc_score(y_test, logreg_proba[:, 1])\n",
        "    logreg_accuracy = accuracy_score(y_test, logreg_classifier.predict(X_test))\n",
        "    logreg_brier_score = brier_score_loss(y_test, logreg_proba[:, 1])\n",
        "    logreg_NetTrust_score = NetTrustScore(y_test, logreg_proba[:, 1][:, np.newaxis])\n",
        "    logreg_max_u_score = max_utility(y_test, logreg_proba[:, 1])\n",
        "\n",
        "    knn_auc = roc_auc_score(y_test, knn_predictions[:, 1])\n",
        "    knn_accuracy = accuracy_score(y_test, knn_classifier.predict(X_test))\n",
        "    knn_brier_score = brier_score_loss(y_test, knn_predictions[:, 1])\n",
        "    knn_NetTrust_score = NetTrustScore(y_test, knn_predictions[:, 1][:, np.newaxis])\n",
        "    knn_max_u_score = max_utility(y_test, knn_predictions[:, 1])\n",
        "\n",
        "    nb_auc = roc_auc_score(y_test, nb_proba[:, 1])\n",
        "    nb_accuracy = accuracy_score(y_test, nb_classifier.predict(X_test))\n",
        "    nb_brier_score = brier_score_loss(y_test, nb_proba[:, 1])\n",
        "    nb_NetTrust_score = NetTrustScore(y_test, nb_proba[:, 1][:, np.newaxis])\n",
        "    nb_max_u_score = max_utility(y_test, nb_proba[:, 1])\n",
        "\n",
        "    # Append the test statistics to the corresponding lists\n",
        "    auc_scores.append([rf_auc, logreg_auc, knn_auc, nb_auc])\n",
        "    accuracy_scores.append([rf_accuracy, logreg_accuracy, knn_accuracy, nb_accuracy])\n",
        "    brier_scores.append([rf_brier_score, logreg_brier_score, knn_brier_score, nb_brier_score])\n",
        "    NetTrust_score.append([rf_NetTrust_score, logreg_NetTrust_score, knn_NetTrust_score, nb_NetTrust_score])\n",
        "    max_utility_scores.append([rf_max_u_score, logreg_max_u_score, knn_max_u_score, nb_max_u_score])"
      ],
      "metadata": {
        "id": "QC7nbiXuwYha",
        "outputId": "8395ac51-d082-4a7b-d648-4b5e2a999d0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\n",
            "Iteration 1\n",
            "Iteration 2\n",
            "Iteration 3\n",
            "Iteration 4\n",
            "Iteration 5\n",
            "Iteration 6\n",
            "Iteration 7\n",
            "Iteration 8\n",
            "Iteration 9\n",
            "Iteration 10\n",
            "Iteration 11\n",
            "Iteration 12\n",
            "Iteration 13\n",
            "Iteration 14\n",
            "Iteration 15\n",
            "Iteration 16\n",
            "Iteration 17\n",
            "Iteration 18\n",
            "Iteration 19\n",
            "Iteration 20\n",
            "Iteration 21\n",
            "Iteration 22\n",
            "Iteration 23\n",
            "Iteration 24\n",
            "Iteration 25\n",
            "Iteration 26\n",
            "Iteration 27\n",
            "Iteration 28\n",
            "Iteration 29\n",
            "Iteration 30\n",
            "Iteration 31\n",
            "Iteration 32\n",
            "Iteration 33\n",
            "Iteration 34\n",
            "Iteration 35\n",
            "Iteration 36\n",
            "Iteration 37\n",
            "Iteration 38\n",
            "Iteration 39\n",
            "Iteration 40\n",
            "Iteration 41\n",
            "Iteration 42\n",
            "Iteration 43\n",
            "Iteration 44\n",
            "Iteration 45\n",
            "Iteration 46\n",
            "Iteration 47\n",
            "Iteration 48\n",
            "Iteration 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average and variance for each test statistic\n",
        "auc_avg = np.mean(auc_scores, axis=0)\n",
        "auc_var = np.std(auc_scores, axis=0)\n",
        "\n",
        "accuracy_avg = np.mean(accuracy_scores, axis=0)\n",
        "accuracy_var = np.std(accuracy_scores, axis=0)\n",
        "\n",
        "brier_avg = np.mean(brier_scores, axis=0)\n",
        "brier_var = np.std(brier_scores, axis=0)\n",
        "\n",
        "NetTrust_avg = np.mean(NetTrust_score, axis=0)\n",
        "NetTrust_var = np.std(NetTrust_score, axis=0)\n",
        "\n",
        "umax_avg = np.mean(max_utility_scores, axis=0)\n",
        "umax_var = np.std(max_utility_scores, axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\" Measure, RF, LR, knn, NB\")\n",
        "print(\"AUC & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(auc_avg[0], auc_var[0], auc_avg[1], auc_var[1], auc_avg[2], auc_var[2], auc_avg[3],  auc_var[3]))\n",
        "print(\"Accuracy & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(accuracy_avg[0], accuracy_var[0], accuracy_avg[1], accuracy_var[1], accuracy_avg[2], accuracy_var[2], accuracy_avg[3],  accuracy_var[3]))\n",
        "print(\"Brier & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(brier_avg[0], brier_var[0], brier_avg[1], brier_var[1], brier_avg[2], brier_var[2], brier_avg[3],  brier_var[3]))\n",
        "print(\"NetTrust & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(NetTrust_avg[0][0], NetTrust_var[0][0], NetTrust_avg[1][0], NetTrust_var[1][0], NetTrust_avg[2][0], NetTrust_var[2][0], NetTrust_avg[3][0],  NetTrust_var[0][0]))\n",
        "print(\"Max Utility & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(umax_avg[0], umax_var[0], umax_avg[1], umax_var[1], umax_avg[2], umax_var[2], umax_avg[3],  umax_var[3]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgEdsu-c64Cj",
        "outputId": "bb3d2610-079e-40bd-945a-fb8dc91fe3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Measure, RF, LR, knn, NB\n",
            "AUC & $0.989 \\pm 0.009$ & $0.990 \\pm 0.007$ & $0.974 \\pm 0.013$ & $0.988 \\pm 0.007$\n",
            "Accuracy & $0.955 \\pm 0.018$ & $0.946 \\pm 0.017$ & $0.903 \\pm 0.025$ & $0.940 \\pm 0.022$\n",
            "Brier & $0.036 \\pm 0.010$ & $0.039 \\pm 0.012$ & $0.078 \\pm 0.014$ & $0.056 \\pm 0.020$\n",
            "NetTrust & $0.618 \\pm 0.040$ & $0.618 \\pm 0.040$ & $0.665 \\pm 0.028$ & $0.628 \\pm 0.040$\n",
            "Max Utility & $0.966 \\pm 0.016$ & $0.961 \\pm 0.015$ & $0.935 \\pm 0.022$ & $0.956 \\pm 0.016$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the average and variance for each test statistic\n",
        "auc_avg = np.mean(auc_scores, axis=0)\n",
        "auc_var = np.std(auc_scores, axis=0)\n",
        "\n",
        "accuracy_avg = np.mean(accuracy_scores, axis=0)\n",
        "accuracy_var = np.std(accuracy_scores, axis=0)\n",
        "\n",
        "brier_avg = np.mean(brier_scores, axis=0)\n",
        "brier_var = np.std(brier_scores, axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\"AUC - Random Forest: {:.4f}, Logistic Regression: {:.4f},  KNN: {:.4f}, Naive Bayes: {:.4f}\".format(auc_avg[0], auc_avg[1], auc_avg[2], auc_avg[3]))\n",
        "print(\"AUC Std - Random Forest: {:.4f}, Logistic Regression: {:.4f},  KNN: {:.4f}, Naive Bayes: {:.4f}\".format(auc_var[0], auc_var[1], auc_var[2], auc_var[3]))\n",
        "\n",
        "print(\"Accuracy - Random Forest: {:.4f}, Logistic Regression: {:.4f}, KNN: {:.4f}, Naive Bayes: {:.4f}\".format(accuracy_avg[0], accuracy_avg[1], accuracy_avg[2], accuracy_avg[3]))\n",
        "print(\"Accuracy Std - Random Forest: {:.4f}, Logistic Regression: {:.4f}, KNN: {:.4f}, Naive Bayes: {:.4f}\".format(accuracy_var[0], accuracy_var[1], accuracy_var[2], accuracy_var[3]))\n",
        "\n",
        "print(\"Brier Score - Random Forest: {:.4f}, Logistic Regression: {:.4f},  KNN: {:.4f}, Naive Bayes: {:.4f}\".format(brier_avg[0], brier_avg[1], brier_avg[2], brier_avg[3]))\n",
        "print(\"Brier Score Std - Random Forest: {:.4f}, Logistic Regression: {:.4f}, KNN: {:.4f}, Naive Bayes: {:.4f}\".format(brier_var[0], brier_var[1], brier_var[2], brier_var[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHjVG1Rcanzs",
        "outputId": "01a797fe-9b13-4629-861c-7fa7fa37598b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC - Random Forest: 0.7972, Logistic Regression: 0.7885,  KNN: 0.7846, Naive Bayes: 0.7803\n",
            "AUC Std - Random Forest: 0.0035, Logistic Regression: 0.0040,  KNN: 0.0034, Naive Bayes: 0.0040\n",
            "Accuracy - Random Forest: 0.7317, Logistic Regression: 0.7357, KNN: 0.7313, Naive Bayes: 0.7229\n",
            "Accuracy Std - Random Forest: 0.0045, Logistic Regression: 0.0049, KNN: 0.0035, Naive Bayes: 0.0038\n",
            "Brier Score - Random Forest: 0.1819, Logistic Regression: 0.1767,  KNN: 0.1796, Naive Bayes: 0.1939\n",
            "Brier Score Std - Random Forest: 0.0012, Logistic Regression: 0.0019, KNN: 0.0016, Naive Bayes: 0.0029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adult Dataset"
      ],
      "metadata": {
        "id": "x04-3_8ySctc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/ritwikvashistha/utrustworthy/main/Datasets/adult.csv\")\n",
        "#data=data.sample(frac=0.02,random_state=1)\n",
        "# Convert categorical variables into one-hot encoding\n",
        "categorical = ['workclass', 'education', 'marital-status', 'occupation',\n",
        "               'relationship', 'race', 'gender', 'native-country', 'income']\n",
        "for name in categorical:\n",
        "    one_hot = pd.get_dummies(data[name], prefix=name)\n",
        "    data = data.drop(name, axis=1)\n",
        "    data = data.join(one_hot)\n",
        "\n",
        "# Split data into X and y\n",
        "y = data['income_<=50K'].values\n",
        "X = data.drop(['income_<=50K','income_>50K'], axis=1).values\n",
        "\n",
        "\n",
        "# Scale X\n",
        "scaler = preprocessing.StandardScaler().fit(X)\n",
        "X = scaler.transform(X)"
      ],
      "metadata": {
        "id": "PCXswvxHSioH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store test statistics for each split\n",
        "auc_scores = []\n",
        "accuracy_scores = []\n",
        "brier_scores = []\n",
        "NetTrust_score = []\n",
        "max_utility_scores = []\n",
        "\n",
        "# Set the number of sims\n",
        "num_sims = 50\n",
        "\n",
        "# Initialize classifiers\n",
        "rf_classifier = RandomForestClassifier(max_depth=3, n_estimators=200)\n",
        "logreg_classifier = LogisticRegression()\n",
        "knn_classifier = KNeighborsClassifier(weights = 'distance', n_neighbors=250)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Perform 20 random splits and evaluate each classifier\n",
        "for i in range(num_sims):\n",
        "\n",
        "    print(\"Iteration %i\"%i)\n",
        "\n",
        "    # Randomly split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45323+i*543)\n",
        "\n",
        "    # Train the classifiers\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    logreg_classifier.fit(X_train, y_train)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and probability estimates\n",
        "    rf_proba = rf_classifier.predict_proba(X_test)\n",
        "    logreg_proba = logreg_classifier.predict_proba(X_test)\n",
        "    knn_predictions = knn_classifier.predict_proba(X_test)\n",
        "    nb_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "    # Calculate test statistics for each classifier\n",
        "    rf_auc = roc_auc_score(y_test, rf_proba[:, 1])\n",
        "    rf_accuracy = accuracy_score(y_test, rf_classifier.predict(X_test))\n",
        "    rf_brier_score = brier_score_loss(y_test, rf_proba[:, 1])\n",
        "    rf_NetTrust_score = NetTrustScore(y_test, rf_proba[:, 1][:, np.newaxis])\n",
        "    rf_max_u_score = max_utility(y_test, rf_proba[:, 1])\n",
        "\n",
        "    logreg_auc = roc_auc_score(y_test, logreg_proba[:, 1])\n",
        "    logreg_accuracy = accuracy_score(y_test, logreg_classifier.predict(X_test))\n",
        "    logreg_brier_score = brier_score_loss(y_test, logreg_proba[:, 1])\n",
        "    logreg_NetTrust_score = NetTrustScore(y_test, logreg_proba[:, 1][:, np.newaxis])\n",
        "    logreg_max_u_score = max_utility(y_test, logreg_proba[:, 1])\n",
        "\n",
        "    knn_auc = roc_auc_score(y_test, knn_predictions[:, 1])\n",
        "    knn_accuracy = accuracy_score(y_test, knn_classifier.predict(X_test))\n",
        "    knn_brier_score = brier_score_loss(y_test, knn_predictions[:, 1])\n",
        "    knn_NetTrust_score = NetTrustScore(y_test, knn_predictions[:, 1][:, np.newaxis])\n",
        "    knn_max_u_score = max_utility(y_test, knn_predictions[:, 1])\n",
        "\n",
        "    nb_auc = roc_auc_score(y_test, nb_proba[:, 1])\n",
        "    nb_accuracy = accuracy_score(y_test, nb_classifier.predict(X_test))\n",
        "    nb_brier_score = brier_score_loss(y_test, nb_proba[:, 1])\n",
        "    nb_NetTrust_score = NetTrustScore(y_test, nb_proba[:, 1][:, np.newaxis])\n",
        "    nb_max_u_score = max_utility(y_test, nb_proba[:, 1])\n",
        "\n",
        "    # Append the test statistics to the corresponding lists\n",
        "    auc_scores.append([rf_auc, logreg_auc, knn_auc, nb_auc])\n",
        "    accuracy_scores.append([rf_accuracy, logreg_accuracy, knn_accuracy, nb_accuracy])\n",
        "    brier_scores.append([rf_brier_score, logreg_brier_score, knn_brier_score, nb_brier_score])\n",
        "    NetTrust_score.append([rf_NetTrust_score, logreg_NetTrust_score, knn_NetTrust_score, nb_NetTrust_score])\n",
        "    max_utility_scores.append([rf_max_u_score, logreg_max_u_score, knn_max_u_score, nb_max_u_score])"
      ],
      "metadata": {
        "id": "8FpwuFQkTDXg",
        "outputId": "2ee8404e-438c-4416-8260-b051acd0844e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\n",
            "Iteration 1\n",
            "Iteration 2\n",
            "Iteration 3\n",
            "Iteration 4\n",
            "Iteration 5\n",
            "Iteration 6\n",
            "Iteration 7\n",
            "Iteration 8\n",
            "Iteration 9\n",
            "Iteration 10\n",
            "Iteration 11\n",
            "Iteration 12\n",
            "Iteration 13\n",
            "Iteration 14\n",
            "Iteration 15\n",
            "Iteration 16\n",
            "Iteration 17\n",
            "Iteration 18\n",
            "Iteration 19\n",
            "Iteration 20\n",
            "Iteration 21\n",
            "Iteration 22\n",
            "Iteration 23\n",
            "Iteration 24\n",
            "Iteration 25\n",
            "Iteration 26\n",
            "Iteration 27\n",
            "Iteration 28\n",
            "Iteration 29\n",
            "Iteration 30\n",
            "Iteration 31\n",
            "Iteration 32\n",
            "Iteration 33\n",
            "Iteration 34\n",
            "Iteration 35\n",
            "Iteration 36\n",
            "Iteration 37\n",
            "Iteration 38\n",
            "Iteration 39\n",
            "Iteration 40\n",
            "Iteration 41\n",
            "Iteration 42\n",
            "Iteration 43\n",
            "Iteration 44\n",
            "Iteration 45\n",
            "Iteration 46\n",
            "Iteration 47\n",
            "Iteration 48\n",
            "Iteration 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average and variance for each test statistic\n",
        "auc_avg = np.mean(auc_scores, axis=0)\n",
        "auc_var = np.std(auc_scores, axis=0)\n",
        "\n",
        "accuracy_avg = np.mean(accuracy_scores, axis=0)\n",
        "accuracy_var = np.std(accuracy_scores, axis=0)\n",
        "\n",
        "brier_avg = np.mean(brier_scores, axis=0)\n",
        "brier_var = np.std(brier_scores, axis=0)\n",
        "\n",
        "NetTrust_avg = np.mean(NetTrust_score, axis=0)\n",
        "NetTrust_var = np.std(NetTrust_score, axis=0)\n",
        "\n",
        "umax_avg = np.mean(max_utility_scores, axis=0)\n",
        "umax_var = np.std(max_utility_scores, axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\" Measure, RF, LR, knn, NB\")\n",
        "print(\"AUC & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(auc_avg[0], auc_var[0], auc_avg[1], auc_var[1], auc_avg[2], auc_var[2], auc_avg[3],  auc_var[3]))\n",
        "print(\"Accuracy & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(accuracy_avg[0], accuracy_var[0], accuracy_avg[1], accuracy_var[1], accuracy_avg[2], accuracy_var[2], accuracy_avg[3],  accuracy_var[3]))\n",
        "print(\"Brier & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(brier_avg[0], brier_var[0], brier_avg[1], brier_var[1], brier_avg[2], brier_var[2], brier_avg[3],  brier_var[3]))\n",
        "print(\"NetTrust & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(NetTrust_avg[0][0], NetTrust_var[0][0], NetTrust_avg[1][0], NetTrust_var[1][0], NetTrust_avg[2][0], NetTrust_var[2][0], NetTrust_avg[3][0],  NetTrust_var[0][0]))\n",
        "print(\"Max Utility & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(umax_avg[0], umax_var[0], umax_avg[1], umax_var[1], umax_avg[2], umax_var[2], umax_avg[3],  umax_var[3]))\n"
      ],
      "metadata": {
        "id": "4lZFSsubTwTR",
        "outputId": "810a6323-3187-496e-b161-e0bc0e63733e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Measure, RF, LR, knn, NB\n",
            "AUC & $0.890 \\pm 0.004$ & $0.906 \\pm 0.003$ & $0.879 \\pm 0.004$ & $0.860 \\pm 0.005$\n",
            "Accuracy & $0.792 \\pm 0.005$ & $0.853 \\pm 0.003$ & $0.834 \\pm 0.003$ & $0.581 \\pm 0.034$\n",
            "Brier & $0.130 \\pm 0.002$ & $0.102 \\pm 0.002$ & $0.116 \\pm 0.002$ & $0.415 \\pm 0.034$\n",
            "NetTrust & $0.703 \\pm 0.002$ & $0.735 \\pm 0.003$ & $0.720 \\pm 0.002$ & $0.756 \\pm 0.002$\n",
            "Max Utility & $0.846 \\pm 0.004$ & $0.853 \\pm 0.003$ & $0.836 \\pm 0.003$ & $0.765 \\pm 0.004$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bankruptcy Dataset"
      ],
      "metadata": {
        "id": "ZgwzzU8hWsuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/ritwikvashistha/utrustworthy/main/Datasets/data%202.csv')\n",
        "X = data.drop('Bankrupt?', axis=1)\n",
        "y = data['Bankrupt?']"
      ],
      "metadata": {
        "id": "kVMkic4tWwPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store test statistics for each split\n",
        "auc_scores = []\n",
        "accuracy_scores = []\n",
        "brier_scores = []\n",
        "NetTrust_score = []\n",
        "max_utility_scores = []\n",
        "\n",
        "# Set the number of sims\n",
        "num_sims = 50\n",
        "\n",
        "# Initialize classifiers\n",
        "rf_classifier = RandomForestClassifier(max_depth=3, n_estimators=200)\n",
        "logreg_classifier = LogisticRegression()\n",
        "knn_classifier = KNeighborsClassifier(weights = 'distance', n_neighbors=250)\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Perform 20 random splits and evaluate each classifier\n",
        "for i in range(num_sims):\n",
        "\n",
        "    print(\"Iteration %i\"%i)\n",
        "\n",
        "    # Randomly split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45323+i*543)\n",
        "\n",
        "    # Train the classifiers\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    logreg_classifier.fit(X_train, y_train)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and probability estimates\n",
        "    rf_proba = rf_classifier.predict_proba(X_test)\n",
        "    logreg_proba = logreg_classifier.predict_proba(X_test)\n",
        "    knn_predictions = knn_classifier.predict_proba(X_test)\n",
        "    nb_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "    # Calculate test statistics for each classifier\n",
        "    rf_auc = roc_auc_score(y_test, rf_proba[:, 1])\n",
        "    rf_accuracy = accuracy_score(y_test, rf_classifier.predict(X_test))\n",
        "    rf_brier_score = brier_score_loss(y_test, rf_proba[:, 1])\n",
        "    rf_NetTrust_score = NetTrustScore(np.asarray(y_test), rf_proba[:, 1][:, np.newaxis])\n",
        "    rf_max_u_score = max_utility(y_test, rf_proba[:, 1])\n",
        "\n",
        "    logreg_auc = roc_auc_score(y_test, logreg_proba[:, 1])\n",
        "    logreg_accuracy = accuracy_score(y_test, logreg_classifier.predict(X_test))\n",
        "    logreg_brier_score = brier_score_loss(y_test, logreg_proba[:, 1])\n",
        "    logreg_NetTrust_score = NetTrustScore(np.asarray(y_test), logreg_proba[:, 1][:, np.newaxis])\n",
        "    logreg_max_u_score = max_utility(y_test, logreg_proba[:, 1])\n",
        "\n",
        "    knn_auc = roc_auc_score(y_test, knn_predictions[:, 1])\n",
        "    knn_accuracy = accuracy_score(y_test, knn_classifier.predict(X_test))\n",
        "    knn_brier_score = brier_score_loss(y_test, knn_predictions[:, 1])\n",
        "    knn_NetTrust_score = NetTrustScore(np.asarray(y_test), knn_predictions[:, 1][:, np.newaxis])\n",
        "    knn_max_u_score = max_utility(y_test, knn_predictions[:, 1])\n",
        "\n",
        "    nb_auc = roc_auc_score(y_test, nb_proba[:, 1])\n",
        "    nb_accuracy = accuracy_score(y_test, nb_classifier.predict(X_test))\n",
        "    nb_brier_score = brier_score_loss(y_test, nb_proba[:, 1])\n",
        "    nb_NetTrust_score = NetTrustScore(np.asarray(y_test), nb_proba[:, 1][:, np.newaxis])\n",
        "    nb_max_u_score = max_utility(y_test, nb_proba[:, 1])\n",
        "\n",
        "    # Append the test statistics to the corresponding lists\n",
        "    auc_scores.append([rf_auc, logreg_auc, knn_auc, nb_auc])\n",
        "    accuracy_scores.append([rf_accuracy, logreg_accuracy, knn_accuracy, nb_accuracy])\n",
        "    brier_scores.append([rf_brier_score, logreg_brier_score, knn_brier_score, nb_brier_score])\n",
        "    NetTrust_score.append([rf_NetTrust_score, logreg_NetTrust_score, knn_NetTrust_score, nb_NetTrust_score])\n",
        "    max_utility_scores.append([rf_max_u_score, logreg_max_u_score, knn_max_u_score, nb_max_u_score])"
      ],
      "metadata": {
        "id": "Ky4V_8WoW0L3",
        "outputId": "b31e1076-7ff8-4bcd-d7d0-489cfbf33f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0\n",
            "Iteration 1\n",
            "Iteration 2\n",
            "Iteration 3\n",
            "Iteration 4\n",
            "Iteration 5\n",
            "Iteration 6\n",
            "Iteration 7\n",
            "Iteration 8\n",
            "Iteration 9\n",
            "Iteration 10\n",
            "Iteration 11\n",
            "Iteration 12\n",
            "Iteration 13\n",
            "Iteration 14\n",
            "Iteration 15\n",
            "Iteration 16\n",
            "Iteration 17\n",
            "Iteration 18\n",
            "Iteration 19\n",
            "Iteration 20\n",
            "Iteration 21\n",
            "Iteration 22\n",
            "Iteration 23\n",
            "Iteration 24\n",
            "Iteration 25\n",
            "Iteration 26\n",
            "Iteration 27\n",
            "Iteration 28\n",
            "Iteration 29\n",
            "Iteration 30\n",
            "Iteration 31\n",
            "Iteration 32\n",
            "Iteration 33\n",
            "Iteration 34\n",
            "Iteration 35\n",
            "Iteration 36\n",
            "Iteration 37\n",
            "Iteration 38\n",
            "Iteration 39\n",
            "Iteration 40\n",
            "Iteration 41\n",
            "Iteration 42\n",
            "Iteration 43\n",
            "Iteration 44\n",
            "Iteration 45\n",
            "Iteration 46\n",
            "Iteration 47\n",
            "Iteration 48\n",
            "Iteration 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average and variance for each test statistic\n",
        "auc_avg = np.mean(auc_scores, axis=0)\n",
        "auc_var = np.std(auc_scores, axis=0)\n",
        "\n",
        "accuracy_avg = np.mean(accuracy_scores, axis=0)\n",
        "accuracy_var = np.std(accuracy_scores, axis=0)\n",
        "\n",
        "brier_avg = np.mean(brier_scores, axis=0)\n",
        "brier_var = np.std(brier_scores, axis=0)\n",
        "\n",
        "NetTrust_avg = np.mean(NetTrust_score, axis=0)\n",
        "NetTrust_var = np.std(NetTrust_score, axis=0)\n",
        "\n",
        "umax_avg = np.mean(max_utility_scores, axis=0)\n",
        "umax_var = np.std(max_utility_scores, axis=0)\n",
        "\n",
        "# Print the results\n",
        "print(\" Measure, RF, LR, knn, NB\")\n",
        "print(\"AUC & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(auc_avg[0], auc_var[0], auc_avg[1], auc_var[1], auc_avg[2], auc_var[2], auc_avg[3],  auc_var[3]))\n",
        "print(\"Accuracy & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(accuracy_avg[0], accuracy_var[0], accuracy_avg[1], accuracy_var[1], accuracy_avg[2], accuracy_var[2], accuracy_avg[3],  accuracy_var[3]))\n",
        "print(\"Brier & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(brier_avg[0], brier_var[0], brier_avg[1], brier_var[1], brier_avg[2], brier_var[2], brier_avg[3],  brier_var[3]))\n",
        "print(\"NetTrust & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(NetTrust_avg[0][0], NetTrust_var[0][0], NetTrust_avg[1][0], NetTrust_var[1][0], NetTrust_avg[2][0], NetTrust_var[2][0], NetTrust_avg[3][0],  NetTrust_var[0][0]))\n",
        "print(\"Max Utility & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$ & ${:.3f} \\pm {:.3f}$\".format(umax_avg[0], umax_var[0], umax_avg[1], umax_var[1], umax_avg[2], umax_var[2], umax_avg[3],  umax_var[3]))\n"
      ],
      "metadata": {
        "id": "eA2MlebUYL1D",
        "outputId": "f9bbb9f8-7dd9-4739-e73b-bde437997616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Measure, RF, LR, knn, NB\n",
            "AUC & $0.927 \\pm 0.016$ & $0.576 \\pm 0.039$ & $0.702 \\pm 0.034$ & $0.654 \\pm 0.056$\n",
            "Accuracy & $0.969 \\pm 0.004$ & $0.961 \\pm 0.004$ & $0.968 \\pm 0.004$ & $0.238 \\pm 0.342$\n",
            "Brier & $0.024 \\pm 0.003$ & $0.042 \\pm 0.004$ & $0.031 \\pm 0.004$ & $0.740 \\pm 0.341$\n",
            "NetTrust & $0.051 \\pm 0.003$ & $0.090 \\pm 0.004$ & $0.057 \\pm 0.003$ & $0.058 \\pm 0.003$\n",
            "Max Utility & $0.971 \\pm 0.004$ & $0.968 \\pm 0.004$ & $0.968 \\pm 0.004$ & $0.968 \\pm 0.004$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q3Smm3TVWmcP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}